{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Medical Image Classification\n",
    "\n",
    "**Welcome to the CNN tutorial for Chest X-Ray Image Classification!**\n",
    "\n",
    "This tutorial is based on the article written by Abhinav Saga for *Towards Data Science*. The original article can be found <a href=\"https://towardsdatascience.com/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8\">here</a>.\n",
    "\n",
    "This tutorial requires data hosted on Kaggle.com (<a href=\"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\">source</a>). \n",
    "\n",
    "**You will need to create a verified Kaggle account, download the data and change the source directory in this file.**\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages and Dependencies\n",
    "To get started, we need to import the required packages which the code will use. The architecture of the neural network will use Keras. \n",
    "\n",
    "Keras is a high level machine learning API which uses TensorFlow as a backend. This allows users to focus on implementation from a more blackbox perspective. TensorFlow is much better suited for more whitebox approaches. TensorFlow uses a structure called tensors which a basically n-dimensional arrays or matricies. We can use NumPy arrays to pass to TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as k\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 232\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Images\n",
    "We now need to set an input path from which to load images. **You must change the following line to point to the correct folder on your system.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = \"C:/Datasets/ChestXRay/chest_xray/chest_xray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Filepath\n",
    "You can verify that the path has been set correctly by counting the images from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The for loop below simply counts and displays the number of images in each directory. This gives us an idea of how many images we are dealing with in each set. You should confirm that your output is as follows:<br />\n",
    "`Set: /train` <br />\n",
    "`Normal Images: 1342 ` <br />\n",
    "`Pneumonia Images: 3876` <br />\n",
    "<br />\n",
    "`Set: /val` <br />\n",
    "`Normal Images: 9` <br />\n",
    "`Pneumonia Images: 9` <br />\n",
    "<br />\n",
    "`Set: /test` <br />\n",
    "`Normal Images: 234` <br />\n",
    "`Pneumonia Images: 390` <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in ['/train', '/val', '/test']:\n",
    "    normal = len(os.listdir(inPath + subset + \"/NORMAL\"))\n",
    "    pneumonia = len(os.listdir(inPath + subset + \"/PNEUMONIA\"))\n",
    "    print(\"Set: \" + str(subset) + \"\\nNormal Images: \" + str(normal) + \"\\nPneumonia Images: \" + str(pneumonia) + \"\\n~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "Now that we have confirmed that we have access to the images, we need to process it into sets to that it be passed to the CNN. Abhinav does this by splitting the the images into training, validation and test sets. They also implement a technique called data augmentation. Because deep learning algorithms perform better with more training data, data augmentation is used to increase the size of the dataset used to train the model. This is relatively easy and a dataset size can be quadrupled simply by rotating images 90, 180 and 270 degrees though other methods also exist like flipping pictures. <br />\n",
    "During this next step, a function is defined which augments and processes image data to prepare it to be passed to the model. The data is augmented using a Keras class called ImageDataGenerator which augments imagesets in real-time with the flow_from_directory() method.<br />\n",
    "The function also resizes images and prepares them for the model.\n",
    "<br />\n",
    "<br /> Abhinav uses the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(img_dims, batch_size):\n",
    "    # Data generation objects\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
    "    test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    input_path = inPath\n",
    "    \n",
    "    # This is fed to the network in the specified batch sizes and image dimensions\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "    directory=input_path+'/train', \n",
    "    target_size=(img_dims, img_dims), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary', \n",
    "    shuffle=True)\n",
    "\n",
    "    test_gen = test_val_datagen.flow_from_directory(\n",
    "    directory=input_path+'/test', \n",
    "    target_size=(img_dims, img_dims), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary', \n",
    "    shuffle=True)\n",
    "    \n",
    "    # I will be making predictions off of the test set in one batch size\n",
    "    # This is useful to be able to get the confusion matrix\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "\n",
    "    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n",
    "        for img in (os.listdir(input_path + '/test' + cond)):\n",
    "            img = plt.imread(input_path+'/test'+cond+img)\n",
    "            img = cv2.resize(img, (img_dims, img_dims))\n",
    "            img = np.dstack([img, img, img])\n",
    "            img = img.astype('float32') / 255\n",
    "            if cond=='/NORMAL/':\n",
    "                label = 0\n",
    "            elif cond=='/PNEUMONIA/':\n",
    "                label = 1\n",
    "            test_data.append(img)\n",
    "            test_labels.append(label)\n",
    "        \n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_gen, test_gen, test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "Hyperparameters are parameters that the creator of the algorithm must choose and directly affect model training accuracy. <br />\n",
    "The `img_dims` variable represents the size of the image in pixels that the images will be resized to. Having a larger image size will drastically increase training \n",
    "time is set too high. Too small dimensions, however, results in poor training because information which which to learn is lost from the image when resized. <br />\n",
    "The `epochs` variable represents the number of times the model runs through the complete training set. Too many epochs result in long wait times and may actually reduce the accuracy of the\n",
    "learned model. Too little epochs and the model will not learn enough. <br/>\n",
    "Finally, the `batch_size` variable is that controls the number of training samples to work through before a models internal parameters (like weights) are updated. Having too large a batch size will use a lot more resources and increase training time.<br />\n",
    "<br />\n",
    "The `train_gen`, `test_gen`, `test_data` and `test_labels` variables represent the training and test datasets which will be used to train the model. \n",
    "These variables are set below. We will experiment with different hyperparameters toward the end of this tutorial. For now the defaults remain: <br/>\n",
    "`img_dims = 150\n",
    "epochs = 20\n",
    "batch_size = 32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dims = 150\n",
    "my_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "train_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the CNN Architecture\n",
    "The most important (and fun) step! Keras makes creating neural networks extremely intuitive and easy. In fact, it may seem like all the previous steps are the most difficult to understand initially. <br />\n",
    "To generate this CNN, we must first contruct each layer in the neural network. We'll walk through Abhinav's CNN layer by layer.<br/>\n",
    "But, before we get started, we need to create an input tensor (a matrix) that is the dimensions of the images being used to train the neural network and an added third dimension of 3. This third dimension is due to the three channels used to compose JPEG images (height x width x channel) which are actually three dimensional array data structures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(img_dims, img_dims, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the first layers in the CNN, which takes `inputs`, the JPEG images, as an input. The convolutional layer scans a kernel across the image and produces another tensor which maps the activation of the kernel across the image. This is the first step in feature extraction. The resulting tensor created from this convolutional layer is then passed to another convolutional layer, and the tensor output by this layer is passed to a maxpooling layer that reduces dimensionality of the data and helps the network to learn and extract features from the image produced the convolution. This completes the first convolutional block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first conv block\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second conv block\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Third conv block\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Fourth conv block\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "\n",
    "# Fifth conv block\n",
    "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(rate=0.2)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, an FC layer is present which classifies the features extracted by the previous convolutional layers and passes this information to the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(rate=0.7)(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(units=64, activation='relu')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling The Model\n",
    "Now, we can compile the model. But before we do that, there are some things to consider.<br/>\n",
    "1. Training can take a very long time, from hours possibly to days <br/>\n",
    "2. If training is interupted, then progress is lost <br/>\n",
    "3. We can't know the what the perfect number of epochs is that is high enough to prevent underfitting, but low enough to prevent overfitting \n",
    "\n",
    "\n",
    "In order to prevent losing a model during training, we can implement the `ModelCheckpoint` callback. This call back saves the model after every epoch to a file at specified `filepath`. If the `save_best_only` boolean is set to `True` then the model will save only the best epochs. The `save_weights_only` boolean means that instead of saving all parameters in the model, just the weights of each connection are saved. <br/>\n",
    "<br/>\n",
    "Choosing hyperparameters like epoch, can be done using trial and error, but this is tedious and may cause overfitting if the model is allowed to train for too many epochs. In order to prevent overfitting, we can used both the `ReduceLROnPlateau` and `EarlyStopping` callbacks. The the `ReduceLROnPLateau` callback method reduces the learning rate of the model once learning starts to plateau. The `EarlyStopping` callback stops the training process when a certain metric that is being monitored stops improving.<br/><br/>\n",
    "For `ReduceLROnPlateau`, the value which we'd like to monitor is the model's loss, so `monitor` is set to `val_loss`. The factor value is factor by which the learning rate will be reduced. `patience` is the number of consecutive epochs with no improvements to wait before reducing learning rate, while `verbose` simply provides a warning message saying that the learning rate is being reduced. Finally, `mode` tells the method to look for improvements in increasing loss when set to `'max'`. When set to `'min'`, the method looks for decreasing loss. In total, this method is saying, monitor`val_loss` as it approaches some `max`imum. If the loss fails to increase for `2` consecutive epochs, reduce the learning rate by a factor of `0.3` and warn the user.<br/><br/>\n",
    "For `EarlyStopping`, the value being monitor is again `val_loss`, just as in the previous method. There is also another parameter, `min_delta` which is set to `0.1`. This parameter specifies the minimum change in the monitored value to be concidered an improvement. `mode` is set to `min` this time because we want the method to detect when `val_loss` reduces. Finally, the `patience` parameter is set to 3 so as to not interfere with `ReduceLSOnPlateau`.\n",
    "<br/>\n",
    "<br/>\n",
    "To read more about the <a href=\"https://keras.io/api/callbacks/reduce_lr_on_plateau/\">`ReduceLROnPlateau`</a> and <a href=\"https://keras.io/api/callbacks/early_stopping/\">`EarlyStopping`</a> methods (actually they are classes), then see the appropriate documentation by clicking them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and compiling\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(filepath='xray_model.hdf5', save_best_only=True, save_weights_only=True)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3, mode='min')\n",
    "\n",
    "my_callbacks = [\n",
    "    checkpoint,\n",
    "    lr_reduce,\n",
    "    early_stop\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Finally, we can train the model! \n",
    "<br/>\n",
    "The `model.fit()` method trains the model and stores training history to help visualize and track the training process. \n",
    "<br/>\n",
    "We're using a few parameters here with `model.fit()`. The first, `train_gen`, passes the training set generator which was definined above with the line: <br/>\n",
    "`train_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)`.<br/> \n",
    "Next, the `epochs` parameter sets the number of training runs, epochs, to perform training on. We defined `my_epochs` above to be 100. The `callbacks` parameter is used to set the callbacks we want the program to use during training. These were diffined above as `my_callbacks`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "            train_gen, \n",
    "            epochs=my_epochs,\n",
    "            callbacks=my_callbacks,\n",
    "            # verbose = 1 # Default\n",
    "            validation_data=test_gen, \n",
    "            steps_per_epoch=train_gen.samples // batch_size,\n",
    "            validation_steps=test_gen.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the history, we can create loss and accuracy plots to visualize model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(hist.history[met])\n",
    "    ax[i].plot(hist.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also gather more useful data like accuracy and pricision by calculating a confusion matrix and other test metrics. Abhinav uses the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "preds = model.predict(test_data)\n",
    "\n",
    "acc = accuracy_score(test_labels, np.round(preds))*100\n",
    "cm = confusion_matrix(test_labels, np.round(preds))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print('CONFUSION MATRIX ------------------')\n",
    "print(cm)\n",
    "\n",
    "print('\\nTEST METRICS ----------------------')\n",
    "precision = tp/(tp+fp)*100\n",
    "recall = tp/(tp+fn)*100\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n",
    "\n",
    "print('\\nTRAIN METRIC ----------------------')\n",
    "print('Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Experiment with Hyperparameters\n",
    "Now you can edit the hyperparametes above and re-run the proceeding steps again to observe any changes. <br/>What changes increase training time?<br/> What changes increase accuracy?<br/> Can you outperform your initial result by altering these parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "So you've trained the model, great. But we want to actually use the model that we've trained, otherwise, what good is it?\n",
    "<br/>\n",
    "Luckily, TensorFlow and Keras make it very easy to save a complete model for further use and/or further training later.\n",
    "<br/>\n",
    "This can be done very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model.save('path/to/file/filename')\n",
    "model.save('C:/Models/CNNexample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "Loading a saved model is just as easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model = keras.models.load_model('path/to/file/filename')\n",
    "model = keras.models.load_model('C:/Models/CNNexample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Trained Model\n",
    "Now we can use a trained model (that was loaded, or that you just trained) to make a prediction based on your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "img_path = 'person19_virus_50.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "prediction = model.predict(x)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `[[0.]]` was printed, the model misclassfied the image we passed it. Let's try training it some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "           train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
    "           epochs=20, validation_data=test_gen, \n",
    "           validation_steps=test_gen.samples // batch_size, callbacks=[checkpoint, lr_reduce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the new model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model.save('path/to/file/filename')\n",
    "model.save('CNNexample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Prediction\n",
    "Now, we'll try another prediction. Lets compare predictions that this CNN will make for a normal picture and a picture with pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pneumonia X-ray should score closely to 1\n",
    "img_path = 'pneumonia.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "pred = image.img_to_array(img)\n",
    "pred = np.expand_dims(pred, axis=0)\n",
    "pred = pred.astype('float32')/255\n",
    "\n",
    "prediction = model.predict(pred)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normal X-ray should score closely to 0\n",
    "img_path = 'normal.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "pred = image.img_to_array(img)\n",
    "pred = np.expand_dims(pred, axis=0)\n",
    "pred = pred.astype('float32')/255\n",
    "\n",
    "prediction = model.predict(pred)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONE!\n",
    "Now that you've completed the tutorial, you should go through and experiment with different hyperparameters. <br/><br/>\n",
    "I would recommend considering the following:\n",
    "1. Should both `ReduceLROnPlateau` and `EarlyStopping` be used?\n",
    "2. If both are used, what parameters should be changed to ensure they don't interfere with eachother and still allow the model to train? (hit, you should have at least 10-15 epochs for this particular model with this data to be trained effectively.\n",
    "3. How does adjusting batch size affect learning and the speed of learning?\n",
    "4. What structural changes can be made to the CNN that could make it perform better? (I would definitely exeperiment here with different CNN architectures!)\n",
    "5. After you've experimented with this data, try to modify to the code to use another dataset of your choice. Importantly, if you do so, you must ensure that the images are atleast 150x150 px in size.\n",
    "6. Try changing the CNN to take a larger image size. Does is take longer to train? Is it more accurate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
